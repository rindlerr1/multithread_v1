{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRoOFM22b_ax"
   },
   "source": [
    "## **multi-thread**\n",
    "\n",
    "\"multi-thread\" is a notebook for drawing in, storing, and analyzing **trading data from Alpaca** in a parralel fashion. \n",
    "\n",
    "The code leverages the python libraries **\"websocket-client\"** for streaming data needs, and **\"_thread\"** to run concurrent functions. \n",
    "\n",
    "Core Functions: data streaming, raw storage, active table, trade decisioning\n",
    "\n",
    "Edit: trade decisioning will be focused on capturing the time latency within the application\n",
    "\n",
    "## **key learnings**\n",
    "Communication between functions, using **'_thread'**, with the use of lists is extremely limiting. But, EVERYTHING RUNS\n",
    "\n",
    "Couple that with the need for inifinite loops, and it created situations of conflict between logical if then statements in the code. Need to explore multi-processing, the use of 'threading', and Queue. Which could all solve the issues experience.  \n",
    "\n",
    "Queue is the best practice for communication between threads, not lists :/. The next iteration start here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Edn_Uii9OhA1"
   },
   "outputs": [],
   "source": [
    "import websocket, json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import _thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y-zrbZdt51HN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "helper functions\n",
    "\"\"\"\n",
    "def delete_file(file_name):\n",
    "    #there are a bunch of these 'try's around, basically, the list system to communicate between threads is just\n",
    "    #as terrible as it was made out to be :/ time to figure out queue!\n",
    "    try:\n",
    "        os.remove(os.getcwd()+'/data_staging/'+file_name)\n",
    "        print(\"Deleted \"+file_name)\n",
    "    except: \n",
    "        FileNotFoundError\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FWZX1sAqdNIg"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Streaming\n",
    "The piece of the notebook covers the code for streaming data from Alpaca using their API into a temporary location.\n",
    "\n",
    "Currently, only a list of securities is being pased to the function.  But, that could expand to include different directories for the data \n",
    "stream, or different authenication details (which are currently hardocded :/)\n",
    "\n",
    "\n",
    "TODO:\n",
    "We'll be using lists and queue to communicate between threads.  We need a line or two here to add the new file name to a globally shared list.\n",
    "\"\"\"\n",
    "\n",
    "#securities = [\"T.TSLA\"]\n",
    "def trade_stream(securities, global_list): #websocket alpaca trade data stream\n",
    "    \"\"\"\n",
    "    The websocket listening is based on the tutorial found here:\n",
    "    https://www.youtube.com/watch?v=fIzm57idu3Y&t=695s\n",
    "    \"\"\"\n",
    "\n",
    "    #opeing function  \n",
    "    def on_open(ws):\n",
    "        print(\"opened\")\n",
    "        #dictionaries with \"action\" and \"data\" seem to be the format for the websocket\n",
    "        #authentication data\n",
    "        auth_data = {\"action\": \"authenticate\",\n",
    "                     \"data\":{\"key_id\":'AKSRDKT347RTSHBQOR3E', \n",
    "                               \"secret_key\":'YaUElSsJlg1cJQusGO0IxxudsqsRmkZQAFJ1WkLU'}}\n",
    "\n",
    "        #tells the websocket that were a legitimate subscriber to its data\n",
    "        ws.send(json.dumps(auth_data))\n",
    "        #tells the websocket what data we are looking for specifically\n",
    "        listen_message = {\"action\":\"listen\", \"data\":{\"streams\":securities}} #securities used to be [\"T.TSLA\"]\n",
    "        #actions the listening\n",
    "        ws.send(json.dumps(listen_message))\n",
    "\n",
    "\n",
    "    def on_message(ws, message):\n",
    "        #Alert\n",
    "        print(\"Received Message\".format(datetime.datetime.now()))\n",
    "        #need a timestamp for the message data\n",
    "        time = str(datetime.datetime.now())\n",
    "        #convert the message to dict format\n",
    "        message_dict = eval(message)\n",
    "        #save the file down into the staging area\n",
    "        with open(os.getcwd()+'/data_staging/'+time+'.json', 'w') as json_file:\n",
    "            json.dump(message_dict, json_file)\n",
    "        print(message)\n",
    "\n",
    "        global_list.append(time+'.json')\n",
    "\n",
    "    #where should the websocket be listening\n",
    "    socket = 'wss://data.alpaca.markets/stream'\n",
    "    #create the websocket app\n",
    "    ws = websocket.WebSocketApp(socket,\n",
    "                              on_open=on_open,\n",
    "                              on_message=on_message)\n",
    "    #start the application\n",
    "    ws.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "id": "KCDQzgShfKRT"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Raw Storage\n",
    "This piece of code listens to the shared list of incoming websocket message file names.  It then reads and writes those files into a \"cold \n",
    "storage\" location and appends (deduplicates and blends) the data for an analysis table.\n",
    "\"\"\"\n",
    "def store_data(global_list, raw_list, active_list):\n",
    "  \n",
    "    def read_file(file_name):\n",
    "        #reading needs to be wrapped with 'try' because the while loops re-reference files global_list[0] is static\n",
    "        #because its static, it can satisfy the requirements to be read while also having already been deleted\n",
    "        #but, the requirement to be deleted is such that this bug does not create data loss\n",
    "        try:\n",
    "            #standard json read\n",
    "            with open(os.getcwd()+'/data_staging/'+file_name) as f:\n",
    "                data = json.load(f)\n",
    "        except:\n",
    "            FileNotFoundError\n",
    "        return data\n",
    "\n",
    "    def write_file(file_name, data):\n",
    "        #standard json write\n",
    "        with open(os.getcwd()+'/cold_storage/'+file_name, 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "\n",
    "    def core_table(data): \n",
    "        #check new data against existing analysis table and remove duplicates\n",
    "        #read in existing data\n",
    "        table = pd.read_csv(os.getcwd()+\"/data.csv\")\n",
    "        #define the new records\n",
    "        new_records = pd.DataFrame.from_dict(data['data'])\n",
    "        #append the new records\n",
    "        table = table.append(new_records)\n",
    "        #drop the duplciate trades\n",
    "        table = table.drop_duplicates(subset=['i'])\n",
    "        #write the file down back into the analysis table\n",
    "        table.to_csv(os.getcwd()+\"/data.csv\", index=False)\n",
    "        print(\"Table Updated\")\n",
    "    \n",
    "    #start an infinte loop to house the calling of the above functions\n",
    "    while True:\n",
    "        #check the global_list, it houses files in staging\n",
    "        if len(global_list) > 0:\n",
    "            #read in the file & write it down to storage\n",
    "            data = read_file(global_list[0])\n",
    "            trade_decision('Storage', data)\n",
    "            write_file(global_list[0], data)\n",
    "            #if the data meets requirements, below, which mean the data is a Trade\n",
    "            if ((data['stream'] != \"authorization\") and (data['stream'] != \"listening\")) :\n",
    "                core_table(data)\n",
    "        #create a file_name variable, it would've been better higher in the code but here is fine\n",
    "        file_name = global_list[0]\n",
    "        #check if the file name is in a list which indicates that it has been checked by the other function\n",
    "        if file_name in active_list:\n",
    "            #similar to the issues with read, deletion can sometimes be called in error\n",
    "            try:\n",
    "                delete_file(file_name)\n",
    "                trade_decision('Storage Deleted', data)\n",
    "            except:\n",
    "                FileNotFoundError\n",
    "            #remove the file from the other lists\n",
    "            active_list.remove(file_name)\n",
    "            global_list.remove(file_name)\n",
    "            print(\"Deleted file from Storage function\")\n",
    "        #mark that the file has been processed by this function\n",
    "        raw_list.append(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zC4iU7m4vXt3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Active Table\n",
    "This functions acts to check the newest arriving data against the most current closing price data by symbol\n",
    "\"\"\"\n",
    "def active_data(global_list, raw_list, active_list):\n",
    "  \n",
    "    def read_file(file_name):\n",
    "        #standard json read\n",
    "        with open(os.getcwd()+'/data_staging/'+file_name) as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    #this checks the data in staging against the active data table\n",
    "    def cross_check(data):\n",
    "        #read the active table\n",
    "        active_data = pd.read_csv(os.getcwd()+'/active_data.csv')\n",
    "        #make sure the data isn't one of the websocket messages that isn't a trade\n",
    "        if ((data['stream'] != \"authorization\") and (data['stream'] != \"listening\")) :\n",
    "            #make sure the data has a stock symbol that is within the active table\n",
    "            if data['data']['T'] in active_data['T'].unique():\n",
    "                \n",
    "                #conditionally check that where the active table's stock symbol matches the data...\n",
    "                #that the price and time need to be updated is the timestamp is later in the data than the table\n",
    "                #this effectively creates a most recent price for the symbol\n",
    "                if int(active_data.loc[active_data['T'] == data['data']['T']].reset_index(drop=True)['t'][0]) <  int(data['data']['t']):\n",
    "                    active_data['p'].loc[active_data['T'] == data['data']['T']] = data['data']['p']\n",
    "                    active_data['t'].loc[active_data['T'] == data['data']['T']] = data['data']['t']\n",
    "                    print(\"Active Data Update\")\n",
    "                active_data.to_csv(os.getcwd()+\"/active_data.csv\", index=False)\n",
    "                \n",
    "\n",
    "    while True:\n",
    "        #check the global_list, it houses files in staging\n",
    "        if len(global_list) > 0:\n",
    "            #reading needs to be wrapped with 'try' because the while loops re-reference files global_list[0] is static\n",
    "            #because its static, it can satisfy the requirements to be read while also having already been deleted\n",
    "            #but, the requirement to be deleted is such that this bug does not create data loss\n",
    "            #this strategy is different than storage, where the try was in the read function\n",
    "            #i think this is better, as there might be other functions that are impacted, and this would \n",
    "            #solve as a universal error handler\n",
    "            try:\n",
    "                #read in the file and cross_check the data against the active table\n",
    "                data = read_file(global_list[0])\n",
    "                cross_check(data)\n",
    "                trade_decision('Active', data)\n",
    "                #create a file_name variable, it would've been better higher in the code but here is fine\n",
    "                file_name = global_list[0]\n",
    "                if file_name in raw_list:\n",
    "                    #similar to the issues with read, deletion can sometimes be called in error\n",
    "                    try:\n",
    "                        delete_file(file_name)\n",
    "                        trade_decision('Active Deleted', data)\n",
    "                    except:\n",
    "                        FileNotFoundError\n",
    "                    #remove the file from the other lists\n",
    "                    raw_list.remove(file_name)\n",
    "                    global_list.remove(file_name)\n",
    "                    print(\"Deleted file from Active function\")\n",
    "                #mark that the file has been processed by this function\n",
    "                active_list.append(file_name)\n",
    "            except:\n",
    "                FileNotFoundError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trade Decisioning\n",
    "\n",
    "In the next iteration this will be explored more heavily. :)\n",
    "\n",
    "Here, this is merely a helper function to write down useful snippets of information that are timestamped throughout\n",
    "the other functions.  This will allow for diagnostics down the road without any threat to the underlying logs for \n",
    "each action/milestone within the code itself\n",
    "\n",
    "\"\"\"\n",
    "def trade_decision(function_name, data):\n",
    "    if ((data['stream'] != \"authorization\") and (data['stream'] != \"listening\")) :\n",
    "        #create miniature dictionary of critial data\n",
    "        info_dict = {'function':function_name, #this allows for a lot of customization\n",
    "                        'T':data['data']['T'], #the stock symbol\n",
    "                        'i':data['data']['i'], #the trade id so we can trace a single trade through the system\n",
    "                        't':data['data']['t'], # the trades timestamp, so we can compare latency from start to any point\n",
    "                        'tT':str(datetime.datetime.now())} #the timestamp of the function being called\n",
    "\n",
    "        #standard json write\n",
    "        with open(os.getcwd()+'/trade_latency/'+str(data['data']['i'])+'_'+function_name+'.json', 'w') as json_file:\n",
    "            json.dump(info_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CQX7CJrm9R0F"
   },
   "outputs": [],
   "source": [
    "#create two empty lists that communicate across the two data blending functions... active data and storage\n",
    "raw_list = []\n",
    "active_list = []\n",
    "#load the global list with any existing files currently in staging\n",
    "global_list = os.listdir(os.getcwd()+'/data_staging/')\n",
    "#grabbed the top thirty securities from: https://www.tradingview.com/markets/stocks-usa/market-movers-active/\n",
    "#this list tells the websocket which securities' trades to listen for\n",
    "securities = ['T.SNDL','T.NAKD','T.PLTR','T.NIO','T.FCEL',\\\n",
    "              'T.WORX','T.AAL','T.NAK','T.GE','T.ACB',\\\n",
    "              'T.IDEX','T.WORK','T.CCL','T.AAPL','T.SRNE',\\\n",
    "              'T.NNDM','T.MRNA','T.TSLA','T.APXT','T.ITUB',\\\n",
    "              'T.TTNP','T.RIG','T.RAIL','T.VALE','T.GNUS',\\\n",
    "              'T.TLRY','T.ZOM','T.SPY','T.FSR','T.PFE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _thread.start_new_thread(trade_stream, (securities, global_list,))\n",
    "    _thread.start_new_thread(active_data, (global_list, raw_list, active_list, ))\n",
    "    _thread.start_new_thread(store_data,  (global_list, raw_list, active_list, ))\n",
    "except:\n",
    "    print('Unable to start threads...')\n",
    "\n",
    "while True:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOwlRdHK00gG6FTkGS6WY89",
   "name": "multi-thread.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
